{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import db_handler\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_handler(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    num_tokens = len(tokens)\n",
    "    return tokens, num_tokens\n",
    "\n",
    "def meta_text_handler(row) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the length of a concatenated string of label, title, sub_title, and date_published\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): dataframe with label, title, sub_title, and date_published columns\n",
    "    \n",
    "    Returns:\n",
    "    int: the length of the concatenated string after being encoded with the tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    label = row[\"label\"].replace(\"Descrição de chapéu\",\"\")\n",
    "    title = row[\"title\"]\n",
    "    sub_title = row[\"sub_title\"]\n",
    "    date_published = row[\"date_published\"].replace(\"\\n\",\"\")\n",
    "    label_str = f\"rotulo: {label}\\n\"\n",
    "    title_str = f\"titulo: {title}\\n\"\n",
    "    sub_title_str = f\"sub-titulo: {sub_title}\\n\"\n",
    "    date_published_str = f\"data de publicação: {date_published}\\n\"\n",
    "    post_meta_text = f\"{label_str}{title_str}{sub_title_str}{date_published_str}conteúdo da matéria: \"\n",
    "    post_meta_text_tokens, post_meta_text_lenght = tokens_handler(post_meta_text)\n",
    "    return post_meta_text, post_meta_text_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_text(df: pd.DataFrame, non_body: pd.Series, \n",
    "               non_body_lenght: pd.Series) -> pd.Series:\n",
    "    max_len = 1015\n",
    "    chunks = []\n",
    "    texts = df[\"post_content\"]\n",
    "    for index, text in texts.items():\n",
    "        tokens, num_tokens = tokens_handler(text)\n",
    "        non_body = df.loc[index, \"post_meta_text\"]\n",
    "        non_body_lenght = df.loc[index, \"post_meta_text_lenght\"]\n",
    "        start = 0\n",
    "        end = min(max_len, (num_tokens - non_body_lenght))\n",
    "        while start < num_tokens:\n",
    "            chunk = tokenizer.decode(tokens[start:end])\n",
    "            chunk = f\"#INPUT#\\n{non_body}{chunk}\"\n",
    "            chunk = re.sub(' +', ' ', chunk)\n",
    "            chunks.append(chunk)\n",
    "            start = end\n",
    "            end = min((end + max_len), num_tokens)\n",
    "    output = pd.Series(chunks)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = db_handler.read_table_posts()\n",
    "df = pd.DataFrame(training_data)\n",
    "df[['post_meta_text', 'post_meta_text_lenght']] = df.apply(meta_text_handler, axis=1, result_type=\"expand\")\n",
    "processed_text = slice_text(df, df[\"post_meta_text\"], df[\"post_meta_text_lenght\"])\n",
    "processed_text.to_csv(\"processed_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9cc3dc29c2b6390f77ef89eee57cd29419c0d3feec6a761fd7bf4a26e3547f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
